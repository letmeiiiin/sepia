{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import sounddevice as sd\n",
    "\n",
    "# Index des micros et fréquences supportées\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    dev = p.get_device_info_by_index(i)\n",
    "    print((i,dev['name'],dev['maxInputChannels']))\n",
    "\n",
    "print(sd.query_devices())\n",
    "\n",
    "samplerates = 16000, 32000, 44100, 48000, 96000, 128000\n",
    "device = 1\n",
    "\n",
    "supported_samplerates = []\n",
    "for fs in samplerates:\n",
    "    try:\n",
    "        sd.check_output_settings(device=device, samplerate=fs)\n",
    "    except Exception as e:\n",
    "        print(fs, e)\n",
    "    else:\n",
    "        supported_samplerates.append(fs)\n",
    "print(supported_samplerates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import srt\n",
    "import json\n",
    "import datetime\n",
    "import pyaudio\n",
    "import time\n",
    "import ctypes\n",
    "from multiprocessing import Process, Value, Array\n",
    "import audioop\n",
    "\n",
    "#manager = multiprocessing.Manager()\n",
    "\n",
    "SetLogLevel(-1)\n",
    "model_path = \"../../asr/vosk/model\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "\tprint (f\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in {model_path}\")\n",
    "\texit (1)\n",
    "\n",
    "model = Model(model_path)\n",
    "rec = KaldiRecognizer(model, 16000)\n",
    "rec.SetWords(True)\n",
    "\n",
    "# ASR loop\n",
    "def asr():\n",
    "\tp = pyaudio.PyAudio()\n",
    "\tstream = p.open(input_device_index=1, format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)\n",
    "\tstream.start_stream()\n",
    "\n",
    "\twhile True:\n",
    "\t\tdata = stream.read(4000)\n",
    "\t\t#data = audioop.ratecv(data, 1, 1, 48000, 16000, None)[0]\n",
    "\t\tif len(data) == 0:\n",
    "\t\t\tbreak\n",
    "\t\tif rec.AcceptWaveform(data):\n",
    "\t\t\tresult = rec.FinalResult()\n",
    "\t\t\tprint(result)\n",
    "\t\t\tjres = json.loads(result)\n",
    "\t\t\tif \"result\" in jres:\n",
    "\t\t\t\tsentence = jres[\"text\"]\n",
    "\t\t\t\tif \"photo\" in sentence:\n",
    "\t\t\t\t\tprint(\"mot photo détecté !\")\n",
    "\t\t\t\t\tprint(\":)\")\n",
    "\n",
    "asr()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fe2ef27dfc9a1ea6fa0078a0a9e0d59173743487f7e8ebf74da19875e62726c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sepia-3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
