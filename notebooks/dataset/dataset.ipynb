{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "pd.set_option('display.width', 10000)\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=wDAmezoNHJY\"\n",
    "\n",
    "vid_id = url.partition(\"/watch?v=\")[2]\n",
    "\n",
    "#retrieve auto-generated transcripts\n",
    "transcript_list = YouTubeTranscriptApi.list_transcripts(vid_id)\n",
    "#transcript = transcript_list.find_manually_created_transcript(['fr', 'fr-FR'])  \n",
    "transcript = transcript_list.find_generated_transcript(['fr', 'fr-FR']) \n",
    "if transcript != \"\":\n",
    "    df = pd.DataFrame(transcript.fetch())\n",
    "    #df.to_csv(\"transcript.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] wDAmezoNHJY: Downloading webpage\n",
      "[youtube] wDAmezoNHJY: Downloading android player API JSON\n",
      "[youtube] wDAmezoNHJY: Downloading webpage\n",
      "[youtube] wDAmezoNHJY: Downloading android player API JSON\n",
      "[info] wDAmezoNHJY: Downloading 1 format(s): 251\n",
      "[download] audio/audio.wav has already been downloaded\n",
      "[download] 100% of 22.79MiB\n",
      "[ExtractAudio] Destination: audio/audio.wav\n",
      "Deleting original file audio/audio.orig.wav (pass -k to keep)\n",
      "Download complete !\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from yt_dlp import YoutubeDL\n",
    "from pydub import AudioSegment\n",
    "from subprocess import STDOUT, DEVNULL, call, run\n",
    "\n",
    "# Fetch best quality audio, re-encode to mono, 256kbps 16bit wav\n",
    "# check file bitrate etc... with: ffprobe audio.wav\n",
    "\n",
    "def fetch_encode_wav(url):\n",
    "    video_info = YoutubeDL().extract_info(\n",
    "        url = url,download=False\n",
    "    )\n",
    "\n",
    "    options={\n",
    "        'format':'bestaudio/best',\n",
    "        'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        }],\n",
    "        'postprocessor_args': [\n",
    "            '-ar', '16000',\n",
    "            '-ac', '1',\n",
    "        ],\n",
    "        'prefer_ffmpeg': True,\n",
    "        'keepvideo':False,\n",
    "        'outtmpl':'audio/audio.wav',\n",
    "    }\n",
    "\n",
    "    with YoutubeDL(options) as ydl:\n",
    "        ydl.download([video_info['webpage_url']])\n",
    "\n",
    "    print(\"Download complete !\")\n",
    "\n",
    "fetch_encode_wav(\"https://www.youtube.com/watch?v=wDAmezoNHJY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 occurrence(s) of word : photo\n",
      "total cuts : 25, removed 1 useless cut(s)\n"
     ]
    }
   ],
   "source": [
    "from subprocess import run\n",
    "from pydub import AudioSegment, silence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import os.path\n",
    "\n",
    "pydub_sample_rate = 16000\n",
    "\n",
    "# Keep only clips containing specific word\n",
    "\n",
    "pd.set_option('display.width', 10000)\n",
    "\n",
    "#df = pd.read_csv(\"transcript.csv\")\n",
    "df.insert(2, 'stop', df['start'] + df['duration'], False)\n",
    "\n",
    "# Select rows with matching word regex\n",
    "word = \"photo\"\n",
    "df2 = df[df['text'].str.contains(r'\\b'+word+r'\\b', regex=True)]\n",
    "print(f\"{df2.shape[0]} occurrence(s) of word : {word}\")\n",
    "#print(df2)\n",
    "# Make audio, generate SRT\n",
    "\n",
    "def cut_merge(cuts, audio_in, audio_out):\n",
    "    # Takes a list of tuples as cuts [(start, end)...]\n",
    "\n",
    "    cuts_old = len(cuts) \n",
    "    for i in range(len(cuts)):\n",
    "\n",
    "        if i < len(cuts)-1 and cuts[i][1] == cuts[i+1][0]:\n",
    "            cuts[i+1] = (cuts[i][0], cuts[i+1][1])\n",
    "            cuts.pop(i)\n",
    "\n",
    "    print(f\"total cuts : {len(cuts)}, removed {cuts_old - len(cuts)} useless cut(s)\") \n",
    "\n",
    "    # Opening file and extracting segment\n",
    "    segment = AudioSegment.from_file(audio_in, format=\"wav\", frame_rate=pydub_sample_rate, channels=1)\n",
    "    clips = []\n",
    "\n",
    "    for cut in cuts:\n",
    "        # cut_start, cut_end should be expressed in ms\n",
    "        clips.append(segment[cut[0]*1000:cut[1]*1000])\n",
    "\n",
    "    merged_clips = sum(clips)\n",
    "    merged_clips.export(audio_out, format=\"wav\", parameters=[\"-ar\", str(pydub_sample_rate), \"-ac\", \"1\"])\n",
    "\n",
    "# def rm_silence(audio_in, audio_out):\n",
    "#     # Audio files should be normalized before removing silence, else manually set top_db everytime ???????\n",
    "\n",
    "#     # Define a function to normalize a chunk to a target amplitude.\n",
    "#     def match_target_amplitude(aChunk, target_dBFS):\n",
    "#         ''' Normalize given audio chunk '''\n",
    "#         change_in_dBFS = target_dBFS - aChunk.dBFS\n",
    "#         return aChunk.apply_gain(change_in_dBFS)\n",
    "\n",
    "#     # Split track where the silence is 2 seconds or more and get chunks using \n",
    "#     # the imported function.\n",
    "#     chunks = silence.split_on_silence (\n",
    "#         AudioSegment.from_wav(audio_in, frame_rate=16000, channels=1), \n",
    "#         # Specify that a silent chunk must be at least 500ms long.\n",
    "#         min_silence_len = 500,\n",
    "#         # Consider a chunk silent if it's quieter than -30 dBFS.\n",
    "#         # (You may want to adjust this parameter.)\n",
    "#         silence_thresh = -30\n",
    "#     )\n",
    "\n",
    "#     #print(chunks)\n",
    "#     print(\"CHONKS :\")\n",
    "#     print(len(chunks))\n",
    "\n",
    "#     silence_length = 1000\n",
    "#     segments = []\n",
    "#     for i, chunk in enumerate(chunks):\n",
    "#         # Create a silence chunk of silence_length ms for smoother transitions (optional)\n",
    "#         silence_chunk = AudioSegment.silent(duration=silence_length)\n",
    "\n",
    "#         # Add silence chunk.\n",
    "#         audio_chunk = silence_chunk + chunk + silence_chunk\n",
    "\n",
    "#         # Normalize the entire chunk.\n",
    "#         normalized_chunk = match_target_amplitude(audio_chunk, -20.0)\n",
    "#         segments.append(normalized_chunk)\n",
    "    \n",
    "#     merged_chunks = sum(segments)\n",
    "#     merged_chunks.export(audio_out, format=\"wav\", frame_rate=16000, channels=1)\n",
    "\n",
    "\n",
    "cut_merge([(start_time,stop_time) for start_time,stop_time in zip(df2['start'], df2[\"stop\"])], \"audio/audio.wav\", \"audio/audio_clip.wav\")\n",
    "#rm_silence(\"audio/audio_clip.wav\", \"audio/audio_clip_unsilenced.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vosk to get words timestamp\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import srt\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "SetLogLevel(-1)\n",
    "\n",
    "if not os.path.exists(\"model\"):\n",
    "    print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n",
    "    exit (1)\n",
    "\n",
    "sample_rate=16000\n",
    "model = Model(\"model\")\n",
    "rec = KaldiRecognizer(model, sample_rate)\n",
    "rec.SetWords(True)\n",
    "audio_clip = \"audio/audio_clip.wav\"\n",
    "\n",
    "process = subprocess.Popen(['ffmpeg', '-loglevel', 'quiet', '-i',\n",
    "                            audio_clip,\n",
    "                            '-ar', str(sample_rate) , '-ac', '1', '-f', 's16le', '-'],\n",
    "                            stdout=subprocess.PIPE)\n",
    "\n",
    "WORDS_PER_LINE = 1\n",
    "\n",
    "def transcribe():\n",
    "    results = []\n",
    "    subs = []\n",
    "    while True:\n",
    "       data = process.stdout.read(4000)\n",
    "       if len(data) == 0:\n",
    "           break\n",
    "       if rec.AcceptWaveform(data):\n",
    "           results.append(rec.Result())\n",
    "    results.append(rec.FinalResult())\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "       jres = json.loads(res)\n",
    "       if not 'result' in jres:\n",
    "           continue\n",
    "       words = jres['result']\n",
    "       for j in range(0, len(words), WORDS_PER_LINE):\n",
    "           line = words[j : j + WORDS_PER_LINE] \n",
    "           s = srt.Subtitle(index=len(subs), \n",
    "                   content=\" \".join([l['word'] for l in line]),\n",
    "                   start=line[0]['start'], \n",
    "                   end=line[-1]['end'])\n",
    "           subs.append(s)\n",
    "    return subs\n",
    "\n",
    "words = transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cuts : 23, removed 0 useless cut(s)\n",
      "23 words transcribed !\n",
      "playing final audio, turn volume up...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5233:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5233:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_hw.c:1829:(_snd_pcm_hw_open) Invalid value for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4745:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5233:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2660:(snd_pcm_open_noupdate) Unknown PCM dmix\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for word in words:\n",
    "    if word.content == \"photo\":\n",
    "        labels.append((word.start, word.end))\n",
    "       \n",
    "cut_merge(labels, \"audio/audio_clip.wav\", \"audio/audio_final.wav\")\n",
    "print(f\"{len(labels)} words transcribed !\")\n",
    "print(\"playing final audio, turn volume up...\")\n",
    "final_segment = AudioSegment.from_wav(\"audio/audio_final.wav\")\n",
    "play(final_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE RUN TIME ~ 50s for (18-21)/26, 30 % error (transcribed/occurences)\n",
    "\n",
    "# Roughly 1 10min vid per minute, 60 vids / hours, if vid = 10min and transcribed = 5 : 60*5 = 300 new words per hour\n",
    "# Worse results when transcribing with unsilenced clip\n",
    "# Still other vosk models to try !"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e87eefdc7f02fbeaa81cb0507323209d5aeafeda9bc03c2b3b93122dcd6ddca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('sepia-3.7.12': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
